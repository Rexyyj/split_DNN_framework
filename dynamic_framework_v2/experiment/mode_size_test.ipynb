{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a939579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5af325",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### setting path ###################################\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "################################### import libs ###################################\n",
    "# from  pytorchyolo import  models_split_large\n",
    "from pytorchyolo import models\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d729bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"../ckpt/yolov3.cfg\"\n",
    "model_path = \"../ckpt/stmarc_full.pth\"\n",
    "\n",
    "split_layer=21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90da3a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Darknet                                  [1, 10647, 85]            --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Sequential: 2-1                   [1, 32, 416, 416]         --\n",
       "│    │    └─Conv2d: 3-1                  [1, 32, 416, 416]         864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 32, 416, 416]         64\n",
       "│    │    └─LeakyReLU: 3-3               [1, 32, 416, 416]         --\n",
       "│    └─Sequential: 2-2                   [1, 64, 208, 208]         --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 208, 208]         18,432\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 208, 208]         128\n",
       "│    │    └─LeakyReLU: 3-6               [1, 64, 208, 208]         --\n",
       "│    └─Sequential: 2-3                   [1, 32, 208, 208]         --\n",
       "│    │    └─Conv2d: 3-7                  [1, 32, 208, 208]         2,048\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 32, 208, 208]         64\n",
       "│    │    └─LeakyReLU: 3-9               [1, 32, 208, 208]         --\n",
       "│    └─Sequential: 2-4                   [1, 64, 208, 208]         --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 208, 208]         18,432\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 208, 208]         128\n",
       "│    │    └─LeakyReLU: 3-12              [1, 64, 208, 208]         --\n",
       "│    └─Sequential: 2-5                   [1, 128, 104, 104]        --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 104, 104]        73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 104, 104]        256\n",
       "│    │    └─LeakyReLU: 3-15              [1, 128, 104, 104]        --\n",
       "│    └─Sequential: 2-6                   [1, 64, 104, 104]         --\n",
       "│    │    └─Conv2d: 3-16                 [1, 64, 104, 104]         8,192\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 64, 104, 104]         128\n",
       "│    │    └─LeakyReLU: 3-18              [1, 64, 104, 104]         --\n",
       "│    └─Sequential: 2-7                   [1, 128, 104, 104]        --\n",
       "│    │    └─Conv2d: 3-19                 [1, 128, 104, 104]        73,728\n",
       "│    │    └─BatchNorm2d: 3-20            [1, 128, 104, 104]        256\n",
       "│    │    └─LeakyReLU: 3-21              [1, 128, 104, 104]        --\n",
       "│    └─Sequential: 2-8                   [1, 64, 104, 104]         --\n",
       "│    │    └─Conv2d: 3-22                 [1, 64, 104, 104]         8,192\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 64, 104, 104]         128\n",
       "│    │    └─LeakyReLU: 3-24              [1, 64, 104, 104]         --\n",
       "│    └─Sequential: 2-9                   [1, 128, 104, 104]        --\n",
       "│    │    └─Conv2d: 3-25                 [1, 128, 104, 104]        73,728\n",
       "│    │    └─BatchNorm2d: 3-26            [1, 128, 104, 104]        256\n",
       "│    │    └─LeakyReLU: 3-27              [1, 128, 104, 104]        --\n",
       "│    └─Sequential: 2-10                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-28                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-29            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-30              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-11                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-31                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-32            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-33              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-12                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-34                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-35            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-36              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-13                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-37                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-38            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-39              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-14                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-40                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-41            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-42              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-15                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-43                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-44            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-45              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-16                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-46                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-48              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-17                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-49                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-51              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-18                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-52                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-53            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-54              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-19                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-55                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-56            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-57              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-20                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-58                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-59            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-60              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-21                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-61                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-62            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-63              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-22                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-64                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-65            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-66              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-23                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-67                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-68            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-69              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-24                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-70                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-71            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-72              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-25                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-73                 [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-74            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-75              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-26                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-76                 [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-77            [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-78              [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-27                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-79                 [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-80            [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-81              [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-28                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-82                 [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-83            [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-84              [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-29                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-85                 [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-86            [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-87              [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-30                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-88                 [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-90              [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-31                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-91                 [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-93              [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-32                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-94                 [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-96              [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-33                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-97                 [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-99              [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-34                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-100                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-101           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-102             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-35                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-103                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-104           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-105             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-36                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-106                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-107           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-108             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-37                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-109                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-110           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-111             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-38                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-112                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-113           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-114             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-39                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-115                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-116           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-117             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-40                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-118                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-119           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-120             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-41                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-121                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-122           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-123             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-42                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-124                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-125           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-126             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-43                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-127                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-128           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-129             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-44                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-130                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-131           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-132             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-45                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-133                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-134           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-135             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-46                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-136                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-137           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-138             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-47                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-139                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-140           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-141             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-48                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-142                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-143           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-144             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-49                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-145                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-146           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-147             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-50                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-148                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-149           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-150             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-51                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-151                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-152           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-153             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-52                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-154                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-155           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-156             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-53                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-157                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-158           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-159             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-54                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-160                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-161           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-162             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-55                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-163                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-164           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-165             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-56                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-166                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-167           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-168             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-57                  [1, 512, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-169                [1, 512, 13, 13]          524,288\n",
       "│    │    └─BatchNorm2d: 3-170           [1, 512, 13, 13]          1,024\n",
       "│    │    └─LeakyReLU: 3-171             [1, 512, 13, 13]          --\n",
       "│    └─Sequential: 2-58                  [1, 1024, 13, 13]         --\n",
       "│    │    └─Conv2d: 3-172                [1, 1024, 13, 13]         4,718,592\n",
       "│    │    └─BatchNorm2d: 3-173           [1, 1024, 13, 13]         2,048\n",
       "│    │    └─LeakyReLU: 3-174             [1, 1024, 13, 13]         --\n",
       "│    └─Sequential: 2-59                  [1, 255, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-175                [1, 255, 13, 13]          261,375\n",
       "│    └─Sequential: 2-60                  --                        --\n",
       "│    │    └─YOLOLayer: 3-176             [1, 507, 85]              --\n",
       "│    └─Sequential: 2-61                  [1, 256, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-177                [1, 256, 13, 13]          131,072\n",
       "│    │    └─BatchNorm2d: 3-178           [1, 256, 13, 13]          512\n",
       "│    │    └─LeakyReLU: 3-179             [1, 256, 13, 13]          --\n",
       "│    └─Sequential: 2-62                  [1, 256, 26, 26]          --\n",
       "│    │    └─Upsample: 3-180              [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-63                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-181                [1, 256, 26, 26]          196,608\n",
       "│    │    └─BatchNorm2d: 3-182           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-183             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-64                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-184                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-185           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-186             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-65                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-187                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-188           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-189             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-66                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-190                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-191           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-192             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-67                  [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-193                [1, 256, 26, 26]          131,072\n",
       "│    │    └─BatchNorm2d: 3-194           [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-195             [1, 256, 26, 26]          --\n",
       "│    └─Sequential: 2-68                  [1, 512, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-196                [1, 512, 26, 26]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-197           [1, 512, 26, 26]          1,024\n",
       "│    │    └─LeakyReLU: 3-198             [1, 512, 26, 26]          --\n",
       "│    └─Sequential: 2-69                  [1, 255, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-199                [1, 255, 26, 26]          130,815\n",
       "│    └─Sequential: 2-70                  --                        --\n",
       "│    │    └─YOLOLayer: 3-200             [1, 2028, 85]             --\n",
       "│    └─Sequential: 2-71                  [1, 128, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-201                [1, 128, 26, 26]          32,768\n",
       "│    │    └─BatchNorm2d: 3-202           [1, 128, 26, 26]          256\n",
       "│    │    └─LeakyReLU: 3-203             [1, 128, 26, 26]          --\n",
       "│    └─Sequential: 2-72                  [1, 128, 52, 52]          --\n",
       "│    │    └─Upsample: 3-204              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-73                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-205                [1, 128, 52, 52]          49,152\n",
       "│    │    └─BatchNorm2d: 3-206           [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-207             [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-74                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-208                [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-209           [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-210             [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-75                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-211                [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-212           [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-213             [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-76                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-214                [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-215           [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-216             [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-77                  [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-217                [1, 128, 52, 52]          32,768\n",
       "│    │    └─BatchNorm2d: 3-218           [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-219             [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-78                  [1, 256, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-220                [1, 256, 52, 52]          294,912\n",
       "│    │    └─BatchNorm2d: 3-221           [1, 256, 52, 52]          512\n",
       "│    │    └─LeakyReLU: 3-222             [1, 256, 52, 52]          --\n",
       "│    └─Sequential: 2-79                  [1, 255, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-223                [1, 255, 52, 52]          65,535\n",
       "│    └─Sequential: 2-80                  --                        --\n",
       "│    │    └─YOLOLayer: 3-224             [1, 8112, 85]             --\n",
       "==========================================================================================\n",
       "Total params: 61,949,149\n",
       "Trainable params: 61,949,149\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 32.93\n",
       "==========================================================================================\n",
       "Input size (MB): 2.08\n",
       "Forward/backward pass size (MB): 619.86\n",
       "Params size (MB): 247.80\n",
       "Estimated Total Size (MB): 869.73\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.load_model(cfg_path, model_path)\n",
    "# model.set_split_layer(split_layer) # layer <7\n",
    "model = model.eval()\n",
    "summary(model, input_size=(1, 3, 416, 416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9208337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "-3\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "8\n",
      "-3\n",
      "9\n",
      "10\n",
      "11\n",
      "11\n",
      "-3\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "-3\n",
      "16\n",
      "17\n",
      "18\n",
      "18\n",
      "-3\n",
      "19\n",
      "20\n",
      "21\n",
      "21\n",
      "-3\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 52, 52])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.rand(1,3, 416,416).cuda()\n",
    "head_output = model(input_tensor,1)\n",
    "head_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f6dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "2\n",
      "-3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_output\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/archiconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/archiconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gitRepo/split_DNN_framework/dynamic_framework_v2/experiment/../../pytorchyolo/models_split_large.py:238\u001b[0m, in \u001b[0;36mDarknet.forward\u001b[0;34m(self, x, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# if mode == 2 and first_shortcut:\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m#     layer_i = layer_i + 1\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m#     first_shortcut = False\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mprint\u001b[39m(layer_i)\n\u001b[0;32m--> 238\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mlayer_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_i\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m module_def[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    240\u001b[0m     x \u001b[38;5;241m=\u001b[39m module[\u001b[38;5;241m0\u001b[39m](x, img_size)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "output = model(head_output,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7009c70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 15.6526,  17.5412,  56.1137,  ...,   0.4709,   0.4709,   0.4709],\n",
       "         [ 48.0860,  17.6755,  56.8738,  ...,   0.4713,   0.4713,   0.4713],\n",
       "         [ 79.9647,  18.0097,  57.0179,  ...,   0.4710,   0.4710,   0.4710],\n",
       "         ...,\n",
       "         [395.9532, 412.0807,  18.6175,  ...,   0.4923,   0.4923,   0.4923],\n",
       "         [403.9572, 412.0856,  18.6066,  ...,   0.4917,   0.4917,   0.4917],\n",
       "         [411.9361, 412.0955,  18.4215,  ...,   0.4866,   0.4866,   0.4866]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cf674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, input_size=(1, 3, 416, 416), dtypes=[torch.float16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "256880db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model,  # your model\n",
    "    {torch.nn.Linear},  # layers to quantize\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88e87f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Darknet                                  [1, 256, 26, 26]          --\n",
       "├─ModuleList: 1-1                        --                        8,459,262\n",
       "│    └─Sequential: 2-1                   [1, 16, 416, 416]         --\n",
       "│    │    └─Conv2d: 3-1                  [1, 16, 416, 416]         432\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 16, 416, 416]         32\n",
       "│    │    └─LeakyReLU: 3-3               [1, 16, 416, 416]         --\n",
       "│    └─Sequential: 2-2                   [1, 16, 208, 208]         --\n",
       "│    │    └─MaxPool2d: 3-4               [1, 16, 208, 208]         --\n",
       "│    └─Sequential: 2-3                   [1, 32, 208, 208]         --\n",
       "│    │    └─Conv2d: 3-5                  [1, 32, 208, 208]         4,608\n",
       "│    │    └─BatchNorm2d: 3-6             [1, 32, 208, 208]         64\n",
       "│    │    └─LeakyReLU: 3-7               [1, 32, 208, 208]         --\n",
       "│    └─Sequential: 2-4                   [1, 32, 104, 104]         --\n",
       "│    │    └─MaxPool2d: 3-8               [1, 32, 104, 104]         --\n",
       "│    └─Sequential: 2-5                   [1, 64, 104, 104]         --\n",
       "│    │    └─Conv2d: 3-9                  [1, 64, 104, 104]         18,432\n",
       "│    │    └─BatchNorm2d: 3-10            [1, 64, 104, 104]         128\n",
       "│    │    └─LeakyReLU: 3-11              [1, 64, 104, 104]         --\n",
       "│    └─Sequential: 2-6                   [1, 64, 52, 52]           --\n",
       "│    │    └─MaxPool2d: 3-12              [1, 64, 52, 52]           --\n",
       "│    └─Sequential: 2-7                   [1, 128, 52, 52]          --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 52, 52]          73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 52, 52]          256\n",
       "│    │    └─LeakyReLU: 3-15              [1, 128, 52, 52]          --\n",
       "│    └─Sequential: 2-8                   [1, 128, 26, 26]          --\n",
       "│    │    └─MaxPool2d: 3-16              [1, 128, 26, 26]          --\n",
       "│    └─Sequential: 2-9                   [1, 256, 26, 26]          --\n",
       "│    │    └─Conv2d: 3-17                 [1, 256, 26, 26]          294,912\n",
       "│    │    └─BatchNorm2d: 3-18            [1, 256, 26, 26]          512\n",
       "│    │    └─LeakyReLU: 3-19              [1, 256, 26, 26]          --\n",
       "==========================================================================================\n",
       "Total params: 8,852,366\n",
       "Trainable params: 8,852,366\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 872.20\n",
       "==========================================================================================\n",
       "Input size (MB): 2.08\n",
       "Forward/backward pass size (MB): 85.84\n",
       "Params size (MB): 1.57\n",
       "Estimated Total Size (MB): 89.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 416, 416)\n",
    "x_q = torch.quantize_per_tensor(x, scale=0.1, zero_point=128, dtype=torch.quint8)\n",
    "\n",
    "summary(model_int8, input_size=(1, 3, 416, 416))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
