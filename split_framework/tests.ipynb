{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_consecutive_bool_tensor(bool_tensor):\n",
    "    \n",
    "    # Convert the boolean tensor to a tensor of integers (0 and 1)\n",
    "    int_tensor = bool_tensor.to(torch.int)\n",
    "    \n",
    "    # Compute the differences between consecutive elements\n",
    "    diff_tensor = torch.diff(int_tensor, prepend=int_tensor[:1])\n",
    "    \n",
    "    # Find positions where the value changes\n",
    "    change_positions = torch.cat((torch.tensor([0],device=\"cuda\"), torch.nonzero(diff_tensor, as_tuple=True)[0], torch.tensor([int_tensor.size(0)],device=\"cuda\")))\n",
    "    \n",
    "    # Calculate the lengths of consecutive runs\n",
    "    run_lengths = torch.diff(change_positions)\n",
    "    \n",
    "    # Identify run lengths that need to be split\n",
    "    over_limit_mask = run_lengths > 255\n",
    "    num_full_chunks = torch.div(run_lengths, 255, rounding_mode='floor')\n",
    "    remainder_chunks = run_lengths % 255\n",
    "\n",
    "    # Build the final tensor with correct sizes\n",
    "    full_chunks = torch.repeat_interleave(torch.tensor([255], dtype=torch.uint8,device=\"cuda\"), num_full_chunks.sum().item())\n",
    "    remainders = remainder_chunks[remainder_chunks > 0].to(torch.uint8)\n",
    "\n",
    "    # Concatenate all parts\n",
    "    final_lengths = torch.cat((full_chunks, remainders))\n",
    "\n",
    "    return final_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_255_values(tensor):\n",
    "    # Find positions of 255 values\n",
    "    is_255 = tensor == 255\n",
    "    changes = torch.diff(is_255.int(), prepend=torch.tensor([0],device=\"cuda\"), append=torch.tensor([0],device=\"cuda\"))\n",
    "\n",
    "    # Start and end positions of consecutive 255 blocks\n",
    "    start_positions = torch.nonzero(changes == 1, as_tuple=True)[0]\n",
    "    end_positions = torch.nonzero(changes == -1, as_tuple=True)[0] - 1\n",
    "\n",
    "    # Compute the cumulative sum for segments with 255 values\n",
    "    mask = is_255.clone()\n",
    "    mask[end_positions + 1] = True  # Include the element after the last 255 in the block\n",
    "    cumsum_tensor = torch.cumsum(tensor * mask, dim=0)\n",
    "    \n",
    "    # Create a tensor to store the merged values\n",
    "    merged_tensor = tensor.clone()\n",
    "\n",
    "    # Add the cumulative sum of 255 blocks to the element after the last 255\n",
    "    merged_tensor[end_positions + 1] += cumsum_tensor[end_positions] - cumsum_tensor[start_positions] + tensor[start_positions]\n",
    "\n",
    "    # Remove the 255 values\n",
    "    mask[start_positions] = False  # Keep the start of each block\n",
    "    merged_tensor = merged_tensor[~is_255 | (is_255 & mask)]\n",
    "\n",
    "    return merged_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_bool_tensor(encoded_list, first_value):\n",
    "       # Convert the encoded list to a PyTorch tensor of uint8\n",
    "\n",
    "    encoded_tensor = torch.tensor(encoded_list, dtype=torch.uint8,device=\"cuda\")\n",
    "    \n",
    "    # Convert encoded_tensor to int32 for repeat_interleave\n",
    "    encoded_tensor = encoded_tensor.to(torch.int32)\n",
    "    tensor_len = 0\n",
    "\n",
    "    while len(encoded_tensor)!=tensor_len:\n",
    "        encoded_tensor = merge_255_values(encoded_tensor)\n",
    "        tensor_len = len(encoded_tensor)\n",
    "    \n",
    "    \n",
    "    # Create an alternating values tensor based on the first value\n",
    "    num_segments = len(encoded_tensor)\n",
    "    values = torch.tensor([first_value], dtype=torch.bool,device=\"cuda\").repeat(num_segments)\n",
    "    values[1::2] = ~values[1::2]  # Flip every other value\n",
    "    \n",
    "    # Create the decoded tensor by repeating each value according to the run lengths\n",
    "    decoded_tensor = torch.repeat_interleave(values, encoded_tensor)\n",
    "    \n",
    "    return decoded_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_tensor[0].cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True, False, False, False],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_tensor = torch.tensor([False] * 300 + [True] * 5 + [False] * 3, dtype=torch.bool,device=\"cuda\")\n",
    "bool_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([255,  45,   5,   3], device='cuda:0', dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "encoded_list = encode_consecutive_bool_tensor(bool_tensor)\n",
    "print(encoded_list)  # Output: [1, 1, 2, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff-\\x05\\x03'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf = encoded_list.cpu().numpy().tobytes()\n",
    "buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255,  45,   5,   3], dtype=uint8)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst = np.frombuffer(buf, dtype=np.uint8)\n",
    "reconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True, False, False, False],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tensor = reconstruct_bool_tensor(reconst, False)\n",
    "decode_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
